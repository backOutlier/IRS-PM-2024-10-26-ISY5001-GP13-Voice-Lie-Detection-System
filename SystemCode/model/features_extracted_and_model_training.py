# -*- coding: utf-8 -*-
"""Features extracted and Model training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZRH9bdlEh7X5k8SMCaZtRGA4RjLwKsc0
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import librosa
import os
import numpy as np

#import annotation file
import pandas as pd
csv_path = '/content/drive/MyDrive/projectisy5001/annotation_filecsv.csv'
df = pd.read_csv(csv_path)
print(df.head())

#examining the label
print(df['Label'].unique())

# Preprocess the 'Label' column
df['Label'] = df['Label'].str.replace(' ', '')  # Remove spaces
df['Label'] = df['Label'].str.lower()  # Convert to lowercase
df['Label'] = df['Label'].str.replace('lie', 'deception') # Replace "lie" with "decep"

print(df.head())
#examine the label again, ensure the clean label
print(df['Label'].unique())

wav_directory = '/content/drive/MyDrive/projectisy5001/audio_files/'
#Features extracting
def extract_features(y, sr):
    try:
        # MFCC
        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

        # MFCC mean,getting its one dimeansion feature
        mfccs_mean = np.mean(mfccs, axis=1)

        return mfccs_mean

    except Exception as e:
        print(f"Error extracting features: {str(e)}")
        return None

#match the wav file to the annotation, and load them
def load_wav_and_extract_features(filename, directory):
    if not filename.endswith('.wav'):
        filename += '.wav'

    file_path = os.path.join(directory, filename)
    #examine that whether the file existing
    if not os.path.exists(file_path):
        print(f"File not found: {file_path}. Skipping...")
        return None

    try:
        y, sr = librosa.load(file_path, sr=None)
        features = extract_features(y, sr)
        return features
    except Exception as e:
        print(f"Error loading {filename}: {str(e)}")
        return None

features = []
for index, row in df.iterrows():
    filename = row[0]
    feature = load_wav_and_extract_features(filename, wav_directory)

    if feature is not None:
        features.append({
            'filename': filename,
            'label': row['Label'],
            'gender': row['Gender'],
            'features': feature
        })

#count the amount of the sample
print(len(features))
type(features)

features_df = pd.DataFrame(features)
# Replace NaN values with a suitable integer
features_df['label'] = features_df['label'].map({'truth': 1, 'deception': 0}).fillna(-1).astype(int)
print(features_df.head())

features_df.head()

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
# Reshape the features before scaling
reshaped_features = np.array(features_df['features'].tolist())
scaled_features = scaler.fit_transform(reshaped_features)
# Replace the original features with the scaled features
features_df['features'] = list(scaled_features)
print(features_df.head())

# Save the features DataFrame to a CSV file
features_df.to_csv('/content/drive/MyDrive/projectisy5001/extracted_features.csv', index=False)

from sklearn.model_selection import train_test_split


X = features_df[['features']]
y = features_df['label']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"train_size and type：{len(X_train)}",type(X_train))
print(f"validation_size：{len(X_test)}")

#training the RF model
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score


rf_classifier = RandomForestClassifier(n_estimators=1000, random_state=42)


X_train_array = np.array([np.array(x[0]) for x in X_train.values])
X_test_array = np.array([np.array(x[0]) for x in X_test.values])


rf_classifier.fit(X_train_array, y_train)

y_pred = rf_classifier.predict(X_test_array)



from sklearn.metrics import classification_report, confusion_matrix


rf_classifier.fit(X_train_array, y_train)

y_pred = rf_classifier.predict(X_test_array)

accuracy = accuracy_score(y_test, y_pred)
print(f"RF_Accuracy：{accuracy}")

# Print the classification report
print(classification_report(y_test, y_pred))

# Print the confusion matrix
print(confusion_matrix(y_test, y_pred))


import numpy as np
# Function to predict deception with probabilities
def predict_deception_with_probabilities(audio_file_path):
    try:
        y, sr = librosa.load(audio_file_path, sr=None)
        features = extract_features(y, sr)
        if features is not None:
            # Reshape the features for prediction
            features = np.array(features).reshape(1, -1)

            # Make the prediction with probabilities
            probabilities = rf_classifier.predict_proba(features)[0]
            truth_probability = probabilities[1]  # Probability of truth (class 1)
            deception_probability = probabilities[0] # Probability of deception (class 0)


            prediction = rf_classifier.predict(features)[0]
            predicted_class = "Truth" if prediction == 1 else "Deception"

            return predicted_class, truth_probability, deception_probability
        else:
            return "Error extracting features", None, None

    except Exception as e:
        return f"Error: {str(e)}", None, None
audio_file_path = '/content/drive/MyDrive/projectisy5001/audio_files/AN_WILTY_EP15_lie10.wav'
predicted_class, truth_probability, deception_probability = predict_deception_with_probabilities(audio_file_path)

print(f"Prediction for {audio_file_path}: {predicted_class}")

if truth_probability is not None and deception_probability is not None:
    print(f"Probability of Truth: {truth_probability:.4f}")
    print(f"Probability of Deception: {deception_probability:.4f}")

# Evaluate the RF Model
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Deception', 'Truth'], yticklabels=['Deception', 'Truth'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix for RF")
plt.show()

import joblib

# Save the trained rf model
joblib.dump(rf_classifier, 'rf_classifier.joblib')

#develop the dataloader for the deeplearning model
import torch
from torch.utils.data import Dataset, DataLoader

class AudioDataset(Dataset):
    def __init__(self, features_df):
        self.features = features_df['features'].values
        self.labels = features_df['label'].values

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        feature = torch.tensor(self.features[idx], dtype=torch.float32)
        label = torch.tensor(self.labels[idx], dtype=torch.long)  # Use long for classification
        return feature, label




# Create datasets
train_dataset = AudioDataset(features_df.iloc[X_train.index]) #use the index of X_train to get corresponding labels
test_dataset = AudioDataset(features_df.iloc[X_test.index])


# Create DataLoaders
train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# Example usage in training loop (replace with your actual model training)
for features, labels in train_dataloader:
    print(f"Feature batch shape: {features.shape}")
    print(f"Label batch shape: {labels.shape}")
    break #remove this to iterate over the whole dataset

import torch
import torch.nn as nn
import torch.optim as optim

# Define the DNN model
class DNN(nn.Module):
    def __init__(self, input_size):
        super(DNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(128, 64)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(64, 2)  # Output layer with 2 classes (truth/deception)


    def forward(self, x):
        x = self.fc1(x)
        x = self.relu1(x)
        x = self.fc2(x)
        x = self.relu2(x)
        x = self.fc3(x)
        return x

# Initialize the model, loss function, and optimizer
input_size = 13  # Number of MFCCs
model = DNN(input_size)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 20
device = torch.device( "cpu")
model.to(device)

for epoch in range(num_epochs):
    for features, labels in train_dataloader:
        features, labels = features.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(features)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

#Evaluate the DNN model
correct = 0
total = 0
with torch.no_grad():
    for features, labels in test_dataloader:
      features, labels = features.to(device), labels.to(device)
      outputs = model(features)
      _, predicted = torch.max(outputs.data, 1)
      total += labels.size(0)
      correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f"Accuracy of the DNN on the test set: {accuracy:.2f}%")

# Get predictions for the test set
y_pred_dnn = []
with torch.no_grad():
    for features, labels in test_dataloader:
        features, labels = features.to(device), labels.to(device)
        outputs = model(features)
        _, predicted = torch.max(outputs.data, 1)
        y_pred_dnn.extend(predicted.cpu().numpy())

# Convert y_test to a list if it's a tensor or numpy array
if isinstance(y_test, torch.Tensor):
    y_test_list = y_test.tolist()
elif isinstance(y_test, np.ndarray):
    y_test_list = y_test.tolist()
else:
    y_test_list = y_test

# Calculate the confusion matrix
cm_dnn = confusion_matrix(y_test_list, y_pred_dnn)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm_dnn, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Deception', 'Truth'], yticklabels=['Deception', 'Truth'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix for DNN")
plt.show()

# Print classification report
print(classification_report(y_test_list, y_pred_dnn))

# Calculate and print other metrics (e.g., precision, recall, F1-score)
from sklearn.metrics import precision_score, recall_score, f1_score

precision = precision_score(y_test_list, y_pred_dnn)
recall = recall_score(y_test_list, y_pred_dnn)
f1 = f1_score(y_test_list, y_pred_dnn)

print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-score: {f1}")

#save the dnn model
torch.save(model.state_dict(), 'dnn_model.pth')

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

param_grid = {
    'C': [0.1, 1, 10, 100],  # Regularization parameter
    'gamma': [1, 0.1, 0.01, 0.001],  # Kernel coefficient
    'kernel': ['rbf', 'linear']  # Kernel type
}

svm_classifier = SVC()
grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')  # 5-fold cross-validation
grid_search.fit(X_train_array, y_train)


best_params = grid_search.best_params_
best_score = grid_search.best_score_

print(f"Best parameters: {best_params}")
print(f"Best cross-validation score: {best_score}")


best_svm_classifier = SVC(**best_params,probability=True)
best_svm_classifier.fit(X_train_array, y_train)


y_pred = best_svm_classifier.predict(X_test_array)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the best SVM on the test set: {accuracy}")

#evaluate the svm model
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming y_test and y_pred are from your best_svm_classifier predictions
y_pred = best_svm_classifier.predict(X_test_array)

# Classification report
print(classification_report(y_test, y_pred, target_names=['Deception', 'Truth']))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Deception', 'Truth'], yticklabels=['Deception', 'Truth'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix for SVM")
plt.show()

# Save the trained SVM model
joblib.dump(best_svm_classifier, 'best_svm_model.joblib')

from sklearn.neighbors import KNeighborsClassifier
# Initialize the KNN classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5)

# Train the classifier
knn_classifier.fit(X_train_array, y_train)

# Make predictions
y_pred = knn_classifier.predict(X_test_array)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"KNN Accuracy: {accuracy}")

print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# evaluate the knn model
y_pred = knn_classifier.predict(X_test_array)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Deception', 'Truth'], yticklabels=['Deception', 'Truth'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix for KNN")
plt.show()

# Save the trained KNN model
joblib.dump(knn_classifier, 'knn_classifier.joblib')

#resemble model_B
import numpy as np
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score

# Load the trained models
rf_classifier = joblib.load('rf_classifier.joblib')
best_svm_classifier = joblib.load('best_svm_model.joblib')
knn_classifier = joblib.load('knn_classifier.joblib')


# Create a soft voting classifier
estimators = [('rf', rf_classifier), ('svm', best_svm_classifier), ('knn', knn_classifier)]
voting_classifier = VotingClassifier(estimators=estimators, voting='soft')


# Reshape features for voting classifier
X_test_array_reshaped = np.array([np.array(x[0]) for x in X_test.values])
# Fit the voting classifier
voting_classifier.fit(X_test_array_reshaped, y_test)

# Predict using soft voting
y_pred_voting = voting_classifier.predict(X_test_array_reshaped)
# Evaluate the voting classifier
accuracy_voting = accuracy_score(y_test, y_pred_voting)
print(f"Voting Classifier Accuracy: {accuracy_voting}")

print(classification_report(y_test, y_pred_voting))

#DNN prediction
dnn_predictions = []
for features in X_test_array_reshaped:
  dnn_predictions.append(dnn_predict(features))
dnn_predictions = np.array(dnn_predictions).reshape(-1)
accuracy_dnn = accuracy_score(y_test, dnn_predictions)
print(f"DNN Accuracy: {accuracy_dnn}")
print(classification_report(y_test, dnn_predictions))

#evaluate resemble model B
cm = confusion_matrix(y_test, y_pred_voting)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Deception', 'Truth'], yticklabels=['Deception', 'Truth'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix for Voting Classifier")
plt.show()

from google.colab import files
import joblib

# Save the trained voting classifier model
joblib.dump(voting_classifier, 'voting_classifier.joblib')

# Download the saved model file
files.download('voting_classifier.joblib')

#resemble model A
# Create a list to store predictions from all models
all_predictions = []

# Get predictions from each model
rf_predictions = rf_classifier.predict(X_test_array)
svm_predictions = best_svm_classifier.predict(X_test_array)
knn_predictions = knn_classifier.predict(X_test_array)


# DNN predictions (already calculated in the provided code)
dnn_predictions = []
for features in X_test_array:
    dnn_predictions.append(dnn_predict(features))
dnn_predictions = np.array(dnn_predictions).reshape(-1)

# Combine predictions into a single array
all_predictions.append(rf_predictions)
all_predictions.append(svm_predictions)
all_predictions.append(knn_predictions)
all_predictions.append(dnn_predictions)
all_predictions = np.array(all_predictions)


# Implement soft voting
# Calculate the average probability for each class across the models
averaged_probabilities = np.mean(all_predictions, axis = 0)

# Predict based on the class with highest averaged probability
ensemble_predictions = np.round(averaged_probabilities).astype(int)

# Evaluate the ensemble model A
accuracy_ensemble = accuracy_score(y_test, ensemble_predictions)
print(f"Ensemble Model Accuracy: {accuracy_ensemble}")
print(classification_report(y_test, ensemble_predictions))

cm = confusion_matrix(y_test, ensemble_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Deception', 'Truth'], yticklabels=['Deception', 'Truth'])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix for Ensemble Model")
plt.show()